{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://alyydi:****@tratonregistry.jfrog.io/artifactory/api/pypi/ats-pypi-virtual/simple\n",
      "Requirement already satisfied: langchain in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (0.2.17)\n",
      "Requirement already satisfied: langchain-community in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (0.2.19)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.43 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (0.2.43)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (0.1.143)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: numpy<2,>=1; python_version < \"3.12\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from pydantic<3,>=1->langchain) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1; python_version < \"3.13\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (24.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.15.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version < \"3.13\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.43->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: anyio in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.5.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2; python_version < \"3.11\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = ''\n",
    "os.environ['OPENAI_API_KEY'] = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46130/7330639.py:8: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  print(response(messages))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Large Language Models (LLMs) represent a cutting-edge advancement in the field of artificial intelligence, particularly in natural language processing. These models are designed to handle vast amounts of text data and utilize deep learning algorithms to generate human-like text responses. LLMs are capable of understanding context, generating coherent responses, and even engaging in meaningful conversations with users. Due to their ability to process and analyze large amounts of text data, LLMs have a wide range of practical applications, including language translation, content' response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 25, 'total_tokens': 125, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None} id='run-285c215e-9310-4536-90f4-edbfb54e946a-0'\n"
     ]
    }
   ],
   "source": [
    "response = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1, max_tokens=100)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='You are an expert in data science'),\n",
    "    HumanMessage(content='Write a paragraph about LLMs')\n",
    "]\n",
    "\n",
    "print(response(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46130/2312250596.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  llm = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0.7, max_tokens=50)\n",
      "/tmp/ipykernel_46130/2312250596.py:13: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  response = llm(prompt.format(language='Python', task='function to calculate an average'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def calculate_average(numbers):\n",
      "    total = sum(numbers) # calculates the sum of all numbers in the list\n",
      "    average = total / len(numbers) # divides the sum by the number of elements in the list\n",
      "    return average\n",
      "\n",
      "# example\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0.7, max_tokens=50)\n",
    "\n",
    "template = '''\n",
    "You are an expert coder.\n",
    "Write a program in {language} to {task}\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = ['language', 'task'],\n",
    "    template = template\n",
    ")\n",
    "\n",
    "response = llm(prompt.format(language='Python', task='function to calculate an average'))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46130/3931579385.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
      "/tmp/ipykernel_46130/3931579385.py:22: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = seq_chain.run('Pythagorean Theorem')\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m\n",
      "a^2 + b^2 = c^2\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "The equation a^2 + b^2 = c^2 is known as the Pythagorean theorem. It states that in a right triangle, the square of the length of the hypotenuse (the side opposite the right angle) is\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "llm1 = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0.7, max_tokens=50)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables = ['description'],\n",
    "    template = '''\n",
    "        You are a great mathematician.\n",
    "        Write the equation of {description}\n",
    "        '''\n",
    ")\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "llm2 = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0.7, max_tokens=50)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables = ['equation'],\n",
    "    template = '''\n",
    "        Write an explanation for this equation: {equation}\n",
    "        '''\n",
    ")\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
    "\n",
    "seq_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "\n",
    "response = seq_chain.run('Pythagorean Theorem')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
