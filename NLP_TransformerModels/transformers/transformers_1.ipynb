{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://alyydi:****@tratonregistry.jfrog.io/artifactory/api/pypi/ats-pypi-virtual/simple\n",
      "Requirement already up-to-date: nltk in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (3.9.1)\n",
      "Requirement already up-to-date: gensim==4.2.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (4.2.0)\n",
      "Requirement already up-to-date: keras-nlp in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (0.6.1)\n",
      "Requirement already up-to-date: keras-preprocessing in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already up-to-date: tensorflow-text>=2.11 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: click in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from nltk) (4.66.6)\n",
      "Requirement already satisfied, skipping upgrade: regex>=2021.8.3 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from gensim==4.2.0) (1.24.4)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from gensim==4.2.0) (7.0.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from gensim==4.2.0) (1.10.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-nlp) (24.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-nlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-core in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-nlp) (0.1.5)\n",
      "Requirement already satisfied, skipping upgrade: rich in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-nlp) (13.9.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-preprocessing) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow-text>=2.11) (2.13.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-hub>=0.8.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow-text>=2.11) (0.16.1)\n",
      "Requirement already satisfied, skipping upgrade: wrapt in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim==4.2.0) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: dm-tree in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-core->keras-nlp) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: namex in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-core->keras-nlp) (0.0.8)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-core->keras-nlp) (3.11.0)\n",
      "Requirement already satisfied, skipping upgrade: pygments<3.0.0,>=2.13.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from rich->keras-nlp) (2.18.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown-it-py>=2.2.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from rich->keras-nlp) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions<5.0,>=4.0.0; python_version < \"3.11\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from rich->keras-nlp) (4.12.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.34.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (4.25.5)\n",
      "Requirement already satisfied, skipping upgrade: flatbuffers>=23.1.21 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (24.3.25)\n",
      "Requirement already satisfied, skipping upgrade: astunparse>=1.6.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.14,>=2.13 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0,>=1.24.3 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (1.67.1)\n",
      "Requirement already satisfied, skipping upgrade: gast<=0.4.0,>=0.2.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: keras<2.14,>=2.13.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.13.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.14,>=2.13.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: libclang>=13.0.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (18.1.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (44.0.0)\n",
      "Requirement already satisfied, skipping upgrade: tf-keras>=2.14.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow-hub>=0.8.0->tensorflow-text>=2.11) (2.15.1)\n",
      "Requirement already satisfied, skipping upgrade: mdurl~=0.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel<1.0,>=0.23.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.45.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.7)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.8.0,>=0.7.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.7.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<1.1,>=0.5 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.32.3)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=1.0.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.0.6)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<3,>=1.6.3 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.36.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=4.4; python_version < \"3.10\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (8.5.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2024.8.30)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<3,>=1.21.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.2.3)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.1.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.1.5)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (4.9)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<6.0,>=2.0.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (5.5.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=3.20 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.20.2)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.7.0,>=0.4.6 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk 'gensim==4.2.0' 'keras-nlp' 'keras-preprocessing' 'tensorflow-text>=2.11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 08:32:08.683686: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-12 08:32:08.726817: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-12 08:32:11.461944: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-12 08:32:11.461981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: VDL900341\n",
      "2024-11-12 08:32:11.461985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: VDL900341\n",
      "2024-11-12 08:32:11.462121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2024-11-12 08:32:11.462150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.183.6\n",
      "[nltk_data] Downloading package punkt to /home/alyydi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda, ELU, Conv1D, MaxPooling1D, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import preprocessing\n",
    "from textblob import TextBlob, Word\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import Model, Input\n",
    "import tensorflow_text as tf_text\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import warnings\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "TRACE = False\n",
    "\n",
    "def set_seeds_and_trace():\n",
    "  os.environ['PYTHONHASHSEED'] = '0'\n",
    "  np.random.seed(42)\n",
    "  tf.random.set_seed(42)\n",
    "  random.seed(42)\n",
    "  if TRACE:\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "def set_session_with_gpus_and_cores():\n",
    "  cores = multiprocessing.cpu_count()\n",
    "  gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "  config = tf.compat.v1.ConfigProto( device_count = {'GPU': gpus  , 'CPU': cores} , intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "  sess = tf.compat.v1.Session(config=config)\n",
    "  tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "set_seeds_and_trace()\n",
    "set_session_with_gpus_and_cores()\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Layers\n",
    "\n",
    "![alt text](./trans1.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./seq2seq_w_att.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where we input attention with the hidden state to create another updated hidden state we could input into the next cell. And this worked well on medium sized sentences, but was hard to train and unstable. Now that we know this, the Transformer basicaly tried to get rid of the RNN by using only attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The embedding and positional encoding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./pos_enc_layer.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This comes straight from the paper\n",
    "\n",
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1)\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = PositionalEmbedding(5000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 26, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tf.constant(np.random.randint(1,5000, size=(3,26)))\n",
    "response = pos(input)\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add and normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./add_n_norm.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Use Add layer instead of + to propagate masks\n",
    "\n",
    "We will create a BaseAttention layer that inherits the Add+Norm and then each subclass of attention will implement the correct on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self attention layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./self_att_layer.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    # We need to compare everything with everything, therefore Q, K and V must be the input\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])  # This one comes from the base class\n",
    "    x = self.layernorm(x)  # This one comes from the base class\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 26, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "vocab_size = 5000\n",
    "input = tf.constant(np.random.randint(1,vocab_size, size=(3,26)))\n",
    "\n",
    "# First we apply the PositionalEmbedding to embed into what the attention layer expects\n",
    "pos = PositionalEmbedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Then we do the self attention, the n_heads is arbitrary\n",
    "gsa = GlobalSelfAttention(num_heads=3, key_dim=embedding_dim)\n",
    "\n",
    "\n",
    "response = gsa(pos(input))\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cross attention layer\n",
    "\n",
    "This layer connects the encoder and decoder. This layer is the most straight-forward use of attention in the model, it performs the same task as the attention block in the previous demo (and we will copy it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,  # This is the key part!!\n",
    "        value=context,  # This is the key part!!\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim_es = 100\n",
    "vocab_size_es = 5000\n",
    "\n",
    "embedding_dim_en = 512\n",
    "vocab_size_en = 6000\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_es = tf.constant(np.random.randint(1,vocab_size_es, size=(3,26)))\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "\n",
    "pos_es = PositionalEmbedding(vocab_size_es, embedding_dim_es)\n",
    "pos_en = PositionalEmbedding(vocab_size_en, embedding_dim_en)\n",
    "\n",
    "\n",
    "gsa = GlobalSelfAttention(num_heads=3, key_dim=embedding_dim_es)\n",
    "cross = CrossAttention(num_heads=3, key_dim=embedding_dim_en)\n",
    "\n",
    "\n",
    "context = gsa(pos_es(input_es)) # Forget about the feed forwards\n",
    "\n",
    "response = cross(pos_en(input_en), context=context) # Forget about masked attention for now, assume it is the identity\n",
    "\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The causal self attention layer (Masked Multi Headed Attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./causal_self_att.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only big difference in the masked multi headed attention is that we cannot attend to words in the future, so we will use a mask such that the Nth word can only see the first N-1 words and not all the sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)  # This is the key!\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./causal_self_att_2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notice in the diagram above how the query can only attend the values for the past\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim_en = 512\n",
    "vocab_size_en = 6000\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "\n",
    "pos_en = PositionalEmbedding(vocab_size_en, embedding_dim_en)\n",
    "\n",
    "csa = CausalSelfAttention(num_heads =3, key_dim=embedding_dim_en)\n",
    "\n",
    "response = csa(pos_es(input_en))\n",
    "\n",
    "response.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
