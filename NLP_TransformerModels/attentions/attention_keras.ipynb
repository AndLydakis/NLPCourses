{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://alyydi:****@tratonregistry.jfrog.io/artifactory/api/pypi/ats-pypi-virtual/simple\n",
      "Requirement already up-to-date: nltk in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (3.9.1)\n",
      "Requirement already up-to-date: gensim==4.2.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (4.2.0)\n",
      "Requirement already up-to-date: keras-nlp in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (0.6.1)\n",
      "Requirement already up-to-date: keras-preprocessing in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already up-to-date: tensorflow-text>=2.11 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: click in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied, skipping upgrade: regex>=2021.8.3 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from nltk) (4.66.6)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from gensim==4.2.0) (1.24.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from gensim==4.2.0) (1.10.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from gensim==4.2.0) (7.0.5)\n",
      "Requirement already satisfied, skipping upgrade: keras-core in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-nlp) (0.1.5)\n",
      "Requirement already satisfied, skipping upgrade: absl-py in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-nlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-nlp) (24.1)\n",
      "Requirement already satisfied, skipping upgrade: rich in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-nlp) (13.9.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-preprocessing) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-hub>=0.8.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow-text>=2.11) (0.16.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow-text>=2.11) (2.13.1)\n",
      "Requirement already satisfied, skipping upgrade: wrapt in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim==4.2.0) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: dm-tree in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-core->keras-nlp) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-core->keras-nlp) (3.11.0)\n",
      "Requirement already satisfied, skipping upgrade: namex in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from keras-core->keras-nlp) (0.0.8)\n",
      "Requirement already satisfied, skipping upgrade: markdown-it-py>=2.2.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from rich->keras-nlp) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions<5.0,>=4.0.0; python_version < \"3.11\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from rich->keras-nlp) (4.12.2)\n",
      "Requirement already satisfied, skipping upgrade: pygments<3.0.0,>=2.13.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from rich->keras-nlp) (2.18.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.19.6 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow-hub>=0.8.0->tensorflow-text>=2.11) (5.28.3)\n",
      "Requirement already satisfied, skipping upgrade: tf-keras>=2.14.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow-hub>=0.8.0->tensorflow-text>=2.11) (2.15.1)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.14,>=2.13.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0,>=1.24.3 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (1.67.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.14,>=2.13 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (44.0.0)\n",
      "Requirement already satisfied, skipping upgrade: keras<2.14,>=2.13.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.13.1)\n",
      "Requirement already satisfied, skipping upgrade: astunparse>=1.6.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: gast<=0.4.0,>=0.2.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: libclang>=13.0.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (18.1.1)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: flatbuffers>=23.1.21 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (24.3.25)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.34.0)\n",
      "Requirement already satisfied, skipping upgrade: mdurl~=0.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.45.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<3,>=1.6.3 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.36.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.7)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=1.0.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.0.6)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<1.1,>=0.5 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.8.0,>=0.7.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.7.2)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.32.3)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<6.0,>=2.0.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (5.5.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (4.9)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=4.4; python_version < \"3.10\" in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (8.5.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.1.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.1.5)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2024.8.30)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<3,>=1.21.1 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (2.2.3)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.10)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.7.0,>=0.4.6 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=3.20 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.20.2)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /home/alyydi/pluralsight/venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\"->tensorflow-text>=2.11) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk 'gensim==4.2.0' 'keras-nlp' 'keras-preprocessing' 'tensorflow-text>=2.11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 07:58:31.353847: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-11 07:58:31.399558: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-11 07:58:33.640403: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-11-11 07:58:33.640436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: VDL900341\n",
      "2024-11-11 07:58:33.640440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: VDL900341\n",
      "2024-11-11 07:58:33.640519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2024-11-11 07:58:33.640541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.183.6\n",
      "[nltk_data] Downloading package punkt to /home/alyydi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import sys\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda, ELU, Conv1D, MaxPooling1D, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import preprocessing\n",
    "from textblob import TextBlob, Word\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import Model, Input\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import warnings\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "TRACE = False\n",
    "\n",
    "def set_seeds_and_trace():\n",
    "  os.environ['PYTHONHASHSEED'] = '0'\n",
    "  np.random.seed(42)\n",
    "  tf.random.set_seed(42)\n",
    "  random.seed(42)\n",
    "  if TRACE:\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "def set_session_with_gpus_and_cores():\n",
    "  cores = multiprocessing.cpu_count()\n",
    "  gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "  config = tf.compat.v1.ConfigProto( device_count = {'GPU': gpus  , 'CPU': cores} , intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "  sess = tf.compat.v1.Session(config=config)\n",
    "  tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "set_seeds_and_trace()\n",
    "set_session_with_gpus_and_cores()\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, vocab_size, max_tokens, embedding_dim, dropout_rate):\n",
    "    super().__init__()\n",
    "    self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_tokens)\n",
    "    self.attention = tf.keras.layers.AdditiveAttention()\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "\n",
    "  def call(self, inputs, training=False):\n",
    "\n",
    "    query, value = inputs\n",
    "    # Query embeddings of shape [batch_size, Tq, dimension].\n",
    "    query_embeddings = self.embedding(query)\n",
    "    # Value embeddings of shape [batch_size, Tv, dimension].\n",
    "    value_embeddings = self.embedding(value)\n",
    "    # Notice we could have an embedding for the inputs and another embedding for outputs, we will see more of that later\n",
    "    x = self.attention([query_embeddings, value_embeddings])\n",
    "    x = self.dropout(x, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "    return x\n",
    "\n",
    "  def build_graph(self, max_tokens, embedding_dim):\n",
    "    query_input = tf.keras.Input(shape=(None, max_tokens, embedding_dim), dtype='int32')\n",
    "    value_input = tf.keras.Input(shape=(None, max_tokens, embedding_dim), dtype='int32')\n",
    "    x = (query_input, value_input)\n",
    "    return Model(inputs=x, outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionModel(100, 10, 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pluralsight/venv/lib/python3.8/site-packages/keras/src/engine/training.py:3403\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[1;32m   3372\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[1;32m   3373\u001b[0m \n\u001b[1;32m   3374\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3400\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[1;32m   3401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m-> 3403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3404\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3405\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3407\u001b[0m     )\n\u001b[1;32m   3408\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[1;32m   3409\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3410\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3415\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[1;32m   3416\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 20\n",
    "max_tokens = 10\n",
    "query = tf.constant(np.random.randint(0, embedding_dim, size=(3,max_tokens)))\n",
    "value = tf.constant(np.random.randint(0, embedding_dim, size=(3,max_tokens)))\n",
    "\n",
    "response = model((query,value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 10, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  2000      \n",
      "                                                                 \n",
      " additive_attention (Additi  multiple                  20        \n",
      " veAttention)                                                    \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  2100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4120 (16.09 KB)\n",
      "Trainable params: 4120 (16.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x7f69f028b850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_graph(max_tokens=max_tokens, embedding_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 10, 20, 20   2000      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " additive_attention (Additi  (None, None, 10, 20, 20   20        \n",
      " veAttention)                )                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 10, 20, 20   0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 10, 20, 10   2100      \n",
      "                             0)                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4120 (16.09 KB)\n",
      "Trainable params: 4120 (16.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Head Attention\n",
    "\n",
    "![alt text](./multi_head.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_heads, vocab_size, attention_dim, max_tokens, embedding_dim, dropout_rate):\n",
    "    super().__init__()\n",
    "    self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_tokens)\n",
    "\n",
    "    # key_dim stands for size of each attention head for query and key, we can also pass value_key is K!=V\n",
    "    self.attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=attention_dim, dropout=dropout_rate)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "  def call(self, inputs, training=False):\n",
    "\n",
    "    query, value = inputs\n",
    "    # Query embeddings of shape [batch_size, Tq, dimension].\n",
    "    query_embeddings = self.embedding(query)\n",
    "    # Value embeddings of shape [batch_size, Tv, dimension].\n",
    "    value_embeddings = self.embedding(value)\n",
    "    x, weights = self.attention(query_embeddings, value_embeddings, return_attention_scores=True)  # We return the scores to do our plot!\n",
    "    x = self.dense(x, training=training)\n",
    "    return x, weights\n",
    "\n",
    "  def build_graph(self, max_tokens, embedding_dim):\n",
    "    query_input = tf.keras.Input(shape=(max_tokens, embedding_dim), dtype='int32')\n",
    "    value_input = tf.keras.Input(shape=(max_tokens, embedding_dim), dtype='int32')\n",
    "    x = (query_input, value_input)\n",
    "    return Model(inputs=x, outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=100\n",
    "model = MultiHeadAttentionModel(num_heads=3, vocab_size=vocab_size, attention_dim=2, max_tokens=max_tokens, embedding_dim=embedding_dim, dropout_rate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x7f6ae4ff8970>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_graph(max_tokens=max_tokens, embedding_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = tf.constant(np.random.randint(0,vocab_size, size=(3,max_tokens, 10)))\n",
    "value = tf.constant(np.random.randint(0,vocab_size, size=(3,max_tokens, 10)))\n",
    "\n",
    "response, weights = model((query,value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 10, 10, 100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3, 10, 10, 10, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi_head_attention_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 10, 20, 20)        2000      \n",
      "                                                                 \n",
      " multi_head_attention_1 (Mu  ((None, 10, 20, 20),      518       \n",
      " ltiHeadAttention)            (None, 3, 10, 20, 10,              \n",
      "                             20))                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10, 20, 100)       2100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4618 (18.04 KB)\n",
      "Trainable params: 4618 (18.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
